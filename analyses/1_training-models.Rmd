---
title: "Training models"
output: github_document
date: 2017-11-07
---

# Setup

Load packages

```{r}
library(caret)
library(tidyverse)
library(pROC)
library(stringr)
library(lavaan)
```

# Load training data. 
Exclusion criteria are descibed in data-raw/analyzed_data.md. We are not authorized to make raw data publicly available and the data loaded here is unfortunately not publicly accessible.

```{r message=FALSE, warning=FALSE}
rm(list = ls())
setwd("..")
training_data <- 
  readRDS("data-raw/training_data.rds")
```
These are the 15 categories for the current offence. They are included in the static predictors.

```{r}

# Current offences
offence_variables <-  
  c("o_traffic", "o_assault", "o_homicide", "o_sexual", "o_otherPerson",
  "o_robbery", "o_theft", "o_autoTheft", "o_otherProperty", 
  "o_whitecollar", "o_narcotic", "o_damage", "o_againstOfficer",
  "o_weapon", "o_other")     

# Static predictors as used in training
static_preds <- 
   c("ageFirstSentence_mr", "ageFirst_missing", "ageAtRelease", 
     "ps_escapeHistory", "ps_prisonTerms_mr", "ps_comServiceTerms_mr", 
     "ps_remandTerms_mr", "ps_defaultTerms_mr", "ps_info_missing", 
     offence_variables)

# Dynamic predictors
(rita_items <- 
  stringr::str_subset(names(analyzed_data), "^i_"))

static_n_rita <- c(static_preds, rita_items)

incl_term <- c(static_preds, rita_items, 
               "openPrison", "conditionalReleaseOutcome", 
               "crimeDuringSentence", "supervisedParole")

# Combined vector of all variables: outcomes and predictors
all_variables  <- c(incl_term, "reoffenceThisTerm", "newO_violent")

```

# Creating subsets
(it would be possible to make sure matched pairs are placed in the same fold - we chose not to do this.)

First devide data into a training set and a test set in ratio 3 to 1



Then make 10 sets of 10 folds 
```{r}
# ten_folds_training  <- createFolds(y = training_set$reoffenceThisTerm, k = 10)
# twenty_by_ten_folds <- createMultiFolds(y = training_set$reoffenceThisTerm, k = 10, times = 20)
ten_by_ten_folds <- createMultiFolds(y = training_set$reoffenceThisTerm, k = 10, times = 10)
```


Now set up the cross validation schemes using these folds. 


```{r}

myControl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, 
  verboseIter = TRUE,
  savePredictions = "final",
  index = ten_by_ten_folds)
```






# Create a data frame of all the combinations for the models


```{r}
model_type <- c("glm", "glmnet", "rf")
outcomes   <- c("reoffenceThisTerm", "newO_violent")
predictors <- c("static_preds", "rita_items","static_n_rita", "incl_term")
model_grid <- expand.grid(model_type, outcomes, predictors, 
                         stringsAsFactors = FALSE)
colnames(model_grid) <- c("model_type", "outcome", "predictors")
```

Create a function for writing formulas used in `caret::train`
```{r}
write_formula <- function(outcome, predictors) {
  rhs            <- eval(parse(text = model_grid$predictors))
  tested_formula <- as.formula(paste(outcome, " ~ ", 
                                     paste(rhs, collapse = " + ")))
  return(tested_formula)
}
```



```{r}
model_grid$tested_formula <-
  purrr::map2(
    .x = model_grid$outcome,
    .y = model_grid$predictors,
    .f = ~ write_formula(.x, .y
    )
  )
  
```


```{r}
model_grid$n_preds <-
  purrr::map_int(
    .x = model_grid$predictors,
    .f = ~ length(eval(parse(text = .x)))
    )
  
  
```


Add list of arguments to use with `caret::train`
```{r}
write_arg_list <- function(model_type, outcome, predictors) {
  predictors <- eval(parse(text = predictors))
  if (model_type == "glm") {
    specific_args <- list(x         = training_set[predictors],
                          y         = training_set[[outcome]],
                          method = "glm",
                          family = "binomial",
                          metric    = "ROC",
                          trControl = myControl
                          )
    # We seem to need to use the formula method of caret::train
    # Might be because of the factors and ordinal predictors?
  } else if (model_type == "glmnet") {
    specific_args <- list(form      = as.formula(
                            paste(outcome, " ~ ",
                                  paste(predictors, collapse = " + "))),
                          data      = training_set,
                          method    = "glmnet",
                          family    = "binomial",
                          standardize = TRUE,
                          metric    = "ROC",
                          trControl = myControl,
                          tuneGrid = expand.grid(
                            alpha  = c(0, 0.2, 0.4, 0.6, 0.8, 1),
                            lambda = seq(0, 3, by = 0.02))
                          )
  } else if (model_type == "rf") {
    # m_try sequency depending on number of predictors
    # includes sqrt() (i.e. 4/8), other powers are 1/8 increments
    n_preds <- length(predictors)
    m_try_seq <- round(n_preds^((1:7)/8))
    specific_args <- list(x         = training_set[predictors],
                          y         = training_set[[outcome]],
                          method    = "rf",
                          metric    = "ROC",
                          trControl = myControl,
                          tuneGrid  = expand.grid(mtry = m_try_seq)
                          )
  }
  
return(specific_args)
}


model_grid$specific_args <-
  purrr::pmap(
    .l = list(
      model_type = model_grid$model_type,
      outcome    = model_grid$outcome,
      predictors = model_grid$predictors
      ),
    .f = ~ write_arg_list(..1, ..2, ..3)
  )
```
Write a function for naming models

```{r}
write_mod_names <- function(model_grid) {
  m <- model_grid$model_type
  o <- model_grid$outcome
  p <- model_grid$predictors
  
  o <- ifelse(o == "reoffenceThisTerm", "G_", "V_")
  p <- ifelse(p == "static_preds", "staticp_",
              ifelse(p == "rita_items", "dynamic_",
                     ifelse(p == "static_n_rita", "all-bgn",
                            "incl-te_")))
  model_name <- paste(o, p, m, sep = "")
  return(model_name)
  
  
}

model_grid$model_name <- write_mod_names(model_grid)
```

Split into subsets of models for easier management
```{r}
glm_grid    <- model_grid %>% filter(model_type == "glm")
glmnet_grid <- model_grid %>% filter(model_type == "glmnet")
rf_grid     <- model_grid %>% filter(model_type == "rf")
```
Strip data from the train output.

function
```{r}
strip_data <- function(train_output) {
  train_output$call <- NA
  train_output$trainingData <- NA
  train_output
}
```



```{r}



# glm ---------------
start <- Sys.time()
train_mods_glm    <- map(.x = glm_grid$specific_args, 
                        .f = ~do.call(caret::train, .x))
Sys.time() - start

train_mods_glm <- map(train_mods_glm, strip_data)
names(train_mods_glm) <- glm_grid$model_name
saveRDS(train_mods_glm, file = "train_mods_glm.rds")
rm(train_mods_glm)

# glmnet -------------

start <- Sys.time()
train_mods_glmnet <- map(.x = glmnet_grid$specific_args,
                        .f = ~do.call(caret::train, .x))
Sys.time() - start

train_mods_glmnet <- map(train_mods_glmnet, strip_data)
saveRDS(train_mods_glmnet, file = "train_mods_glmnet.rds")
rm(train_mods_glmnet)

```

```{r}
train_mods_glmnet <-readRDS("train_mods_glmnet")
```

# Updating tuning grid for glmnet models

```{r}
plot(train_mods_glmnet[[1]], ylim = c(0.764, 0.77), xlim = c(0, 0.5))
update_grid_1 <- expand.grid(alpha = seq(0.8, 1, by = 0.04), 
                             lambda = seq(0, 0.05, by = 0.002))
```
```{r}
plot(train_mods_glmnet[[2]], ylim = c(0.75, 0.78), xlim = c(0, 0.5))
update_grid_2 <- expand.grid(alpha = seq(0, 0.2, by = 0.04), 
                             lambda = seq(0, 0.5, by = 0.01))
```
```{r}
plot(train_mods_glmnet[[3]], ylim = c(0.75, 0.76), xlim = c(0, 1))
update_grid_3 <- expand.grid(alpha = seq(0.1, 0.3, by = 0.04), 
                             lambda = seq(0, 0.4, by = 0.01))
```

```{r}
plot(train_mods_glmnet[[4]], ylim = c(0.70, 0.75), xlim = c(0, 1))
update_grid_4 <- expand.grid(alpha = seq(0, 0.2, by = 0.04), 
                             lambda = seq(0, 0.6, by = 0.01))
```
```{r}
plot(train_mods_glmnet[[5]], ylim = c(0.78, 0.80), xlim = c(0, 1))
update_grid_5 <- expand.grid(alpha = seq(0.80, 1, by = 0.04), 
                             lambda = seq(0, 0.2, by = 0.002))
```


```{r}
plot(train_mods_glmnet[[6]], ylim = c(0.78, 0.80), xlim = c(0, 1))
update_grid_6 <- expand.grid(alpha = seq(0, 0.2, by = 0.04), 
                             lambda = seq(0, 0.4, by = 0.002))
```
```{r}
plot(train_mods_glmnet[[7]], ylim = c(0.79, 0.83), xlim = c(0, 1))
update_grid_7 <- expand.grid(alpha = seq(0.8, 1, by = 0.04), 
                             lambda = seq(0, 0.2, by = 0.002))
```

```{r}
plot(train_mods_glmnet[[8]], ylim = c(0.78, 0.81), xlim = c(0, 1))
update_grid_8 <- expand.grid(alpha = seq(0, 0.2, by = 0.02), 
                             lambda = seq(0, 0.3, by = 0.002))
```
```{r}
glmnet_grid$specific_args_2 <- glmnet_grid$specific_args

glmnet_grid$specific_args_2[[1]]$tuneGrid <- update_grid_1
glmnet_grid$specific_args_2[[2]]$tuneGrid <- update_grid_2
glmnet_grid$specific_args_2[[3]]$tuneGrid <- update_grid_3
glmnet_grid$specific_args_2[[4]]$tuneGrid <- update_grid_4
glmnet_grid$specific_args_2[[5]]$tuneGrid <- update_grid_5
glmnet_grid$specific_args_2[[6]]$tuneGrid <- update_grid_6
glmnet_grid$specific_args_2[[7]]$tuneGrid <- update_grid_7
glmnet_grid$specific_args_2[[8]]$tuneGrid <- update_grid_8
```



```{r}
# glmnet -------------

start <- Sys.time()
train_mods_glmnet_2 <- map(.x = glmnet_grid$specific_args_2,
                        .f = ~do.call(caret::train, .x))
Sys.time() - start

train_mods_glmnet_2 <- map(train_mods_glmnet_2, strip_data)
names(train_mods_glmnet_2) <- glmnet_grid$model_name
saveRDS(train_mods_glmnet_2, file = "train_mods_glmnet")
rm(train_mods_glmnet_2)

#rf ------------------

start <- Sys.time()
train_mods_rf     <- map(.x = rf_grid$specific_args, 
                        .f = ~do.call(caret::train, .x))
Sys.time() - start

train_mods_rf <- map(train_mods_rf, strip_data)
names(train_mods_rf) <- rf_grid$model_name
saveRDS(train_mods_rf, file = "train_mods_rf.rds")
rm(train_mods_rf)


```

Save 'grid' data frames
```{r}
saveRDS(glm_grid, file = "glm_grid.rds")
saveRDS(glmnet_grid, file = "glmnet_grid.rds")
saveRDS(rf_grid, file = "rf_grid.rds")
```

